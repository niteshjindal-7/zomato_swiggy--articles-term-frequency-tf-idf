{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc7ba788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a02b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "data0 = pd.read_csv('C:/.../Swiggy-Zomato-Food-Aggregators-Analysis/Articles_Data/Zomato_Articles.csv')\n",
    "data0 = data0.dropna()\n",
    "data00 = pd.read_csv('C:/.../Swiggy-Zomato-Food-Aggregators-Analysis/Articles_Data/Swiggy_Articles.csv') \n",
    "data00 = data00.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f4a63fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "('zoma_bigram_during_incdnt', 'zoma_bigram_after_incdnt', 'zoma_bigram_before_incdnt', 'swgy_bigram_during_incdnt', 'swgy_bigram_after_incdnt', 'swgy_bigram_before_incdnt')\n",
      "1\n",
      "('zoma_bigram_during_incdnt', 'zoma_bigram_after_incdnt', 'zoma_bigram_before_incdnt', 'swgy_bigram_during_incdnt', 'swgy_bigram_after_incdnt', 'swgy_bigram_before_incdnt')\n",
      "2\n",
      "('zoma_bigram_during_incdnt', 'zoma_bigram_after_incdnt', 'zoma_bigram_before_incdnt', 'swgy_bigram_during_incdnt', 'swgy_bigram_after_incdnt', 'swgy_bigram_before_incdnt')\n",
      "3\n",
      "('zoma_bigram_during_incdnt', 'zoma_bigram_after_incdnt', 'zoma_bigram_before_incdnt', 'swgy_bigram_during_incdnt', 'swgy_bigram_after_incdnt', 'swgy_bigram_before_incdnt')\n",
      "4\n",
      "('zoma_bigram_during_incdnt', 'zoma_bigram_after_incdnt', 'zoma_bigram_before_incdnt', 'swgy_bigram_during_incdnt', 'swgy_bigram_after_incdnt', 'swgy_bigram_before_incdnt')\n",
      "5\n",
      "('zoma_bigram_during_incdnt', 'zoma_bigram_after_incdnt', 'zoma_bigram_before_incdnt', 'swgy_bigram_during_incdnt', 'swgy_bigram_after_incdnt', 'swgy_bigram_before_incdnt')\n",
      "--- 4.612818241119385 seconds ---\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Impact Analysis for Zomato delivery boy incident[happened on 11 Dec 2018] and Swiggy Anonymous Blog incident \n",
    "[happened on 26 July 2017] on the two brands. Here we will look into the word frequencies for both the food aggregators.\n",
    "'''\n",
    "\n",
    "#Zomato (get before incidence, during incidence and after incidence data) -\n",
    "Zomato_data_during_incidence = data0[data0.Article_date.str.contains('11 December 2018',case=False)]\n",
    "Zomato_data_after_incidence = data0.loc[:(Zomato_data_during_incidence.index.values[0]-1)]\n",
    "Zomato_data_before_incidence = data0.loc[(Zomato_data_during_incidence.index.values[0]+1):]\n",
    "\n",
    "#Swiggy (get before incidence, during incidence and after incidence data) -\n",
    "Swiggy_data_during_incidence = data00[data00.Article_date.str.contains('26 July 2017',case=False)]\n",
    "Swiggy_data_after_incidence = data00.loc[:(Swiggy_data_during_incidence.index.values[0]-1)]\n",
    "Swiggy_data_before_incidence = data00.loc[(Swiggy_data_during_incidence.index.values[0]+1):]\n",
    "\n",
    "def wordfreq(data):\n",
    "    reviews = data['Article_content']\n",
    "    #reviews0 = list(reviews)\n",
    "    \n",
    "    '''Remove Emails ''' \n",
    "    reviews1 = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in reviews] # Remove emails\n",
    "    reviews1 = [re.sub('\\s+', ' ', sent) for sent in reviews1] # Remove newline character\n",
    "    reviews1 = [re.sub(\"\\'\", \"\", sent) for sent in reviews1] # Remove distracting single quotes\n",
    "    reviews2 = [re.sub('[^A-Za-z0-9]+', ' ', sent) for sent in reviews1] # remove alphanumeric values\n",
    "    \n",
    "    '''Remove numbers ''' \n",
    "    \n",
    "    reviews3 = [''.join(i for i in s if not i.isdigit()) for s in reviews2]\n",
    "    #del reviews1, reviews2\n",
    "    \n",
    "    '''Bigram using CountVectorizer ''' \n",
    "    \n",
    "    vectorizer = CountVectorizer(min_df = 1, ngram_range=(2, 2), stop_words = 'english')\n",
    "    X = vectorizer.fit_transform(reviews3)\n",
    "    df = pd.DataFrame(X.toarray().transpose(), index = vectorizer.get_feature_names())\n",
    "    \n",
    "    frequency = list(df.sum(axis=1))\n",
    "    bigramwords = list(vectorizer.get_feature_names())\n",
    "    \n",
    "    bigram_termfreq= pd.DataFrame({'bigramwords': bigramwords, 'frequency': frequency})\n",
    "    bigram = bigram_termfreq.sort_values(['frequency'], ascending=[False]) #get bigram words and their frequency in document\n",
    "     \n",
    "       #min_df = 2, max_df = 0.70 for before and after incidence. min_df= 1 during incidence.\n",
    "    tf = TfidfVectorizer(min_df = 1, ngram_range=(2, 2), smooth_idf=False, sublinear_tf=False, norm=None, analyzer='word', stop_words = 'english')\n",
    "    txt_fitted = tf.fit(reviews3)\n",
    "    txt_transformed = tf.transform(reviews3)\n",
    "    doc_term_matrix = txt_transformed.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, \n",
    "                      columns= tf.get_feature_names())\n",
    "    \n",
    "    idf = tf.idf_\n",
    "    rr = dict(zip(txt_fitted.get_feature_names(), idf))\n",
    "    token_weight = pd.DataFrame.from_dict(rr, orient='index').reset_index()\n",
    "    token_weight.columns=('word_token','weight')\n",
    "    token_weight = token_weight.sort_values(by='weight', ascending=False)\n",
    "    \n",
    "    return bigram, token_weight\n",
    "    \n",
    "    \n",
    "loop = (Zomato_data_during_incidence.dropna(), Zomato_data_after_incidence.dropna(), Zomato_data_before_incidence.dropna(), \n",
    "Swiggy_data_during_incidence.dropna(), Swiggy_data_after_incidence.dropna(), Swiggy_data_before_incidence.dropna())\n",
    "for i in range(0,len(loop)):\n",
    "    j=(\"zoma_bigram_during_incdnt\", \"zoma_bigram_after_incdnt\", \"zoma_bigram_before_incdnt\",\n",
    "       \"swgy_bigram_during_incdnt\", \"swgy_bigram_after_incdnt\", \"swgy_bigram_before_incdnt\")\n",
    "    print(i)\n",
    "    print(j)\n",
    "    results = wordfreq(loop[i])\n",
    "    bigram_termfreq = results[0] # bigram term frequency, first output of the function\n",
    "    bigram_inversetermfreq = results[1] # bigram inverse term frequency, second output of the function\n",
    "    #if i<3:\n",
    "    with pd.ExcelWriter(\"C:/.../Swiggy-Zomato-Food-Aggregators-Analysis/articles_data/bigrams_output\" + j[i] + \".xlsx\") as writer:\n",
    "        bigram_termfreq.to_excel(writer, sheet_name= 'TermFrequency')  \n",
    "        bigram_inversetermfreq.to_excel(writer, sheet_name= 'tf-idf_weight')\n",
    "            \n",
    "            \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
